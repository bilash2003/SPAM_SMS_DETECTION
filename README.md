ğŸ“© SMS Spam Detection using Machine Learning & BERT

A complete end-to-end SMS Spam Detection System built using
. Natural Language Processing (NLP)
. Machine Learning algorithms (NaÃ¯ve Bayes, SVM, Logistic Regression, etc.)
. TF-IDF Vectorization
. BERT (Transformer-based deep learning model)
. Streamlit for deployment

This project classifies a given SMS message as SPAM or HAM.
ğŸš€ Features
âœ” End-to-end Data Preprocessing
âœ” NLP Pipeline (Tokenization â†’ Stopword Removal â†’ Stemming)
âœ” ML Models Comparison
âœ” TF-IDF Vectorizer
âœ” BERT-based classifier using Transformers
âœ” Visualizations (WordCloud, Histograms, Pairplots)
âœ” Exported Model (model.pkl, vectorizer.pkl)
âœ” Streamlit deployment support

ğŸ“‚ Project Structure
ğŸ“ sms-spam-detection
â”‚â”€â”€ app.py
â”‚â”€â”€ spam.csv
â”‚â”€â”€ model.pkl
â”‚â”€â”€ vectorizer.pkl
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ nltk.txt
â”‚â”€â”€ setup.sh
â”‚â”€â”€ Procfile
â”‚â”€â”€ spam_detection.ipynb
â”‚â”€â”€ README.md (you will paste this file)

ğŸ“Š Dataset Information
Dataset used: SMS Spam Collection Dataset
Source: Contains ~5,500 SMS labelled as "ham" or "spam".
Columns used:
v1 â†’ target (ham/spam)
v2 â†’ text (SMS text)
Unnecessary columns removed:
Unnamed: 2
Unnamed: 3
Unnamed: 4

ğŸ§¹ Data Preprocessing & NLP Pipeline

âœ” Step 1 â€” Cleaning & Renaming Columns
df.drop(columns=['Unnamed: 2','Unnamed: 3','Unnamed: 4'], inplace=True)
df.rename(columns={'v1':'target','v2':'text'}, inplace=True)

âœ” Step 2 â€” Label Encoding
ham â†’ 0  
spam â†’ 1

âœ” Step 3 â€” Remove Duplicates
âœ” Step 4 â€” Feature Engineering

Columns created:
num_characters
num_words
num_sentences

âœ” Step 5 â€” Text Transformation Function
Your pipeline:
Lowercase
Tokenization
Remove special characters
Remove stopwords
Remove punctuation

Apply Porter Stemming

ğŸŒ ML Vectorization Techniques Used
âœ” CountVectorizer

Transforms text â†’ numerical bag-of-words vectors.

âœ” TF-IDF Vectorizer

Used with max_features=3000
This vectorizer gave the best precision.

ğŸ¤– Machine Learning Models Used

You trained & compared the following:

Model	Accuracy	Precision: 
Multinomial Naive Bayes	â­ Best	â­ Best

SVM (Sigmoid Kernel)	Good	High

Logistic Regression	Good	Good

KNN	Moderate	Low

Decision Tree	Moderate	Low

Random Forest	High	Good

AdaBoost	Good	Good

You also built:
âœ” Voting Classifier (Soft Voting)

Models:

SVM
MultinomialNB
ExtraTreesClassifier
âœ” Stacking Classifier
Meta model: RandomForestClassifier
ğŸ¤— BERT / Transformers Model

You fine-tuned:
distilbert-base-uncased
bert-base-uncased

Steps:
Tokenization
Transform into input_ids & attention_mask
Train/test split
Training with Trainer API
Evaluate metrics
Prediction function:

def predict_sms(text):
    inputs = tokenizer(text, return_tensors="pt")
    outputs = model(**inputs)
    probs = softmax(outputs.logits)
    return "SPAM" or "HAM"

ğŸ“ˆ Visualizations Included

Histogram (ham vs spam)

WordCloud for spam

Spam frequent words barplot

Pairplot for feature correlation

ğŸ§ª Model Files

The following files are used for deployment:

model.pkl          â†’ trained ML model  
vectorizer.pkl     â†’ TF-IDF vectorizer  
app.py             â†’ streamlit app  

â–¶ï¸ How to Run Locally
1. Clone the repo
git clone https://github.com/yourusername/sms-spam-detection.git
cd sms-spam-detection

2. Install dependencies
pip install -r requirements.txt

3. Run Streamlit App
streamlit run app.py

ğŸš€ Deployment (Streamlit / Render / Heroku)

Your repo already has:

âœ” Procfile
âœ” setup.sh
âœ” requirements.txt
âœ” nltk.txt

This means your app can be deployed on:

Streamlit Cloud

Push to GitHub

Go to share.streamlit.io

Select repo â†’ select app.py â†’ Deploy

Render / Railway

Supported via Procfile.

ğŸ›  Technologies Used
Programming Language: Python 3.x 

Libraries
Data Handling: numpy  pandas

Visualization: matplotlib seaborn wordcloud

NLP:  nltk stopwords PorterStemmer

ML Models: scikit-learn CountVectorizer TfidfVectorizer

Deep Learning: transformers torch datasets

Deployment: streamlit

ğŸ“Œ Future Improvements
Add LSTM model
Add FastAPI backend
Add continuous monitoring
Improve model interpretability (SHAP)
Add UI enhancements

ğŸ‘¤ Author

Bilash Mallick
B.Tech CSE (AI & ML)
